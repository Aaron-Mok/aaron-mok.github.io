
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta http-equiv="X-UA-Compatible" content="ie=edge"/>
<meta name="theme-color" content="#478079"/>



<title>Aaron Mok | System Architect</title>
<meta name="description" content='This is Aaron Mok&#39;s personal website. He is a System Architect specializing in the design and optimization of complex optical systems.'>
<meta name="generator-mode" content='production'>
<style data-generator="critical-css">
</style>
  <link rel="stylesheet" href="https://aaron-mok.github.io/scss/adritian.min.c43980c726e1de153bec9c6b98a1e28b34cd282522a8f596ab3bb88d4b55c066.css" integrity="sha256-xDmAxybh3hU77JxrmKHiizTNKCUiqPWWqzu4jUtVwGY=" crossorigin="anonymous"/>

<link
  rel="preload"
  href="/css/bundle.min.102305a2784647e8254386fe7c72c7438fa33d258f54fb52032992a991d8caa5.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  integrity="sha256-ECMFonhGR+glQ4b+fHLHQ4+jPSWPVPtSAymSqZHYyqU="
    crossorigin="anonymous"
/>
<noscript>
  <link 
    rel="stylesheet"
    href="/css/bundle.min.102305a2784647e8254386fe7c72c7438fa33d258f54fb52032992a991d8caa5.css"
    integrity="sha256-ECMFonhGR+glQ4b+fHLHQ4+jPSWPVPtSAymSqZHYyqU="
    crossorigin="anonymous"
  />
</noscript>





  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-32S011CNTY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-32S011CNTY');
  </script>



<link rel="icon" href="/icon_cropped_30x30.png" type="image/x-icon" /> 
<style>
 
.math.display + ul,
p.math + ul,
p:has(+ ul) {
  margin-bottom: 0.2em !important;
}

ul {
  margin-top: 0.2em !important;
}

table {
  margin-bottom: 1.0em;
}

p:has(+ mjx-container[display="true"]) {
  margin-bottom: 1.0em !important;
}

mjx-container[display="true"] {
  display: block;
  margin-top: 1.0em !important;    
  margin-bottom: 1.0em !important;
}

 
table + mjx-container[display="true"] {
  margin-top: 2em !important;
}

 
p + mjx-container[display="true"] {
  margin-top: 0em !important;
  margin-bottom: 1.0em !important;
}

ul,
ol {
  margin-top: 1.0em !important;  
  margin-bottom: 1.0em !important;  
}

p:has(+ figure.center) {
  margin-bottom: 0.7em !important;
}

 
figure.center {
  margin-top: 0 !important;
}

 
table td,
table th {
  padding-top: 0.2em !important;
  padding-bottom: 0.2 em !important;
}

.spacer {
  height: 1.0em !important;
}

pre {
  width: 95%;            
  margin: 0em auto;      
}

strong, b {
  font-weight: bold;
}


p:has(+ pre),
p:has(+ div.highlight),
p:has(+ div.chroma) {
  margin-bottom: 0.5em;    
}

pre + h1,
pre + h2,
pre + h3,
div.highlight + h1,
div.highlight + h2,
div.highlight + h3 {
  margin-top: revert;
}

pre + p,
div.highlight + p,
div.chroma + p {
  margin-top: 0.5em;
}

li,
li p {
  line-height: 1.6;  
  margin: 1.0em;         
}

pre + div,
div.highlight + div,
div.chroma + div {
  margin-top: 1.0em;  
}

p + div {
  margin-top: 0.0em;
}

</style>


  
</head>

<body>
  

<header class="header fixed-top rad-animation-group" id="header">
  <div class="container rad-fade-in">
    <nav class="navbar navbar-expand-lg navbar-light p-0">
      <div class="container-fluid">
        <a class="navbar-brand mx-auto" href="https://aaron-mok.github.io/">
          <span>Aaron</span>
          <span>Mok</span>
        </a>
        <button
          class="navbar-toggler collapsed"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarSupportedContent, #header"
          aria-controls="navbarSupportedContent"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav ml-lg-auto">
            <li class="nav-item">
              <a class="nav-link active" href="https://aaron-mok.github.io/">HOME</a>
            </li>
            
            <li class="nav-item">
              <a data-scroll class="nav-link" href="/#about"
                >ABOUT</a
              >
            </li>
            
            <li class="nav-item">
              <a data-scroll class="nav-link" href="/#experience"
                >EXPERIENCE</a
              >
            </li>
            
            <li class="nav-item">
              <a data-scroll class="nav-link" href="/#portfolio"
                >PORTFOLIO</a
              >
            </li>
            
            <li class="nav-item">
              <a data-scroll class="nav-link" href="/blog"
                >BLOG</a
              >
            </li>
            
            <li class="nav-item">
              <a data-scroll class="nav-link" href="/#contact"
                >CONTACT</a
              >
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
  </div>
</header>


<section id="breadcrumb-bar" class="breadcrumb-bar container">
        <ul class="breadcrumbs">
            <li class="breadcrum-item"><span><a href="/">Home</a></span></li><li class="breadcrum-item"><span><a href="/blog">Blog</a></span></li></ul>
</section>


  <main class="blog"> 
    <section class="container section">
      <h1 class="rad-fade-down rad-waiting rad-animate">Blogs</h1>
      <div class="posts-list container">
        
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/camera_isp/">Custom Camera Image Signal Processing (ISP) Pipeline with Raspberry Pi</a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Sun Aug 17, 2025</h4> ¬∑ 
          <h4 id="wordcount">3225 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/CameraISP/CoverArt_3.png" alt="ISP art"></p>
<p>This post presents a custom, real-time camera image signal processing (ISP) pipeline developed from scratch for the Raspberry Pi HQ camera, designed to meet the precise control requirements for future stereo vision applications. The pipeline encompasses raw Bayer capture, stride correction, black level subtraction, demosaicing, white balance, and color correction calibration, and gamma mapping to sRGB. A reusable Python library is provided to support others working with raw data from the Pi HQ camera (See <a href="https://github.com/Aaron-Mok/Stereo-Camera/tree/main">GitHub</a>).</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/camera_isp/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/pianokeydetection/">My AI Piano Tutor</a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Sun Jul 6, 2025</h4> ¬∑ 
          <h4 id="wordcount">2028 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/AIPianoTutor/AITutorCoverArt.png" alt="ToF art"></p>
<p>I am a beginner piano player‚Äîdespite holding ABRSM Grade 8 in both oboe and music theory. Piano presents a new set of challenges. For me, the difficulty lies in sight-reading: identifying notes on both clefs, finding the correct keys on the keyboard, and coordinating both hands in real time. That became the inspiration for this project: building my own AI-powered piano tutor using computer vision, a webcam, and a piano to improve my sight-reading.</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/pianokeydetection/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/bestformlens/">What is the best form lens? </a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Sat May 24, 2025</h4> ¬∑ 
          <h4 id="wordcount">691 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/BestFormLens/bestformlens.png" alt="best form lens art"></p>
<p>I recently came across an interesting question: ‚ÄúWhat is the best form of a singlet lens?‚Äù At first, it seemed trivial ‚Äî the answer is clearly the plano-convex lens. That‚Äôs what many optical design texts suggest, since it minimizes spherical aberration and coma. But I soon discovered that this answer relies on certain assumptions.</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/bestformlens/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/lidar/">Light Detection and Ranging (LiDAR)</a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Sun Jan 12, 2025</h4> ¬∑ 
          <h4 id="wordcount">1144 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/LiDAR/LiDAR.webp" alt="ToF art"></p>
<p>In my last blog post, I discussed optical Time-of-Flight (ToF) sensing and explained how it works with a single emitter that produces a single beam of light and a single-pixel detector. Because of this setup, we could measure the ToF at only one point in space.</p>
<p>The question, then, is: How can we sense depth across an entire area?
The answer lies in Light Detection and Ranging (LiDAR) ‚Äî a system based on ToF that can measure depth over a broad region. In this blog post, I will (a) discuss the fundamentals of LiDAR and (b) demonstrate the optical system of a specific type of LiDAR, Flash LiDAR, using Zemax.</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/lidar/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/solidworks_showcase/">Optics tooling and mounts</a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Wed Jan 8, 2025</h4> ¬∑ 
          <h4 id="wordcount">363 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/Toolings/tooling_coverart.webp" alt="ToF art"></p>
<p>This blog post showcases some optical tooling and mounts I designed in SolidWorks and Fusion.</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/solidworks_showcase/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/time_of_flight/">Optical Time-of-Flight (ToF) sensing and lock-in detection</a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Sat Dec 28, 2024</h4> ¬∑ 
          <h4 id="wordcount">1172 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/ToF/time_of_flight.webp" alt="ToF art"></p>
<p>Distance measurements is important for a lot of applications, such as 3D imaging and depth sensing. One common method for distance measurement is by using optical time-of-flight. I will introduce two concepts: (a) The time-of-flight Principle and (b) lock-in detection/amplification to explain how it works.</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/time_of_flight/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
          <div class="row row--padded rad-animation-group rad-fade-down rad-waiting rad-animate section--border-bottom">
          <article class="post summary col-12">
  <header>
    <h2><a href="/blog/deepscope/">The Dual Excitation with Adaptive Excitation Polygon-scanning Multiphoton Microscope (DEEPscope)</a></h2>
    <div class="post-meta">
      <div>
        <section>
          Published on
          <h4 id="date">Fri Nov 1, 2024</h4> ¬∑ 
          <h4 id="wordcount">322 Words</h4>
        </section>
         
      </div>
    </div>
  </header>
  <div class="post-summary post-content">
  <p><img src="/img/blog/Mouse3Drender.gif" alt="DEEPscope Animation"></p>
<p>In neuroscience research, imaging neuronal activity in the deep brain is crucial for understanding neurological diseases. However, as imaging depth increases, the field of view usually decreases exponentially. We have improved the fluorescence signal generation efficiency of three-photon microscopy, achieving an imaging field two order of magnitudes larger than traditional three-photon microscopes in deep brain regions with cellular resolution.</p>
  </div>

  <footer class="">
    <div class="row">
      <div class="col-12 col-lg-4">
        <a class="btn btn-primary" href="/blog/deepscope/"
          >Read more&nbsp;&raquo;</a
        >
      </div>
    </div>
  </footer>
</article>

          </div>
        
      </div>
    </section>
  </main>

  <footer class="footer">
  <div class="container">
    <div class="footer__left">
      <div class="footer__copy">
        ¬© Aaron Mok. All rights reserved.
      </div>
    </div>
    <div class="footer__links">
      <ul class="navbar-nav ">
        <li class="nav-item">
            <a class="nav-link" href="https://aaron-mok.github.io/">üè† HOME</a>
        </li>
        
      </ul>
    </div>
    <div class="footer__right">
      
    </div>
  </div>
</footer>
 <script>
  window.addEventListener("load", function() {
    try{
      var observer = window.lozad(".lozad", {
        rootMargin: window.innerHeight / 2 + "px 0px",
        threshold: 0.01
      }); 
      observer.observe();
    } catch(e) {
      console.error(e);
    }
  });
</script>
<script defer src='https://aaron-mok.github.io/js/rad-animations.js'></script>
<script defer src='https://aaron-mok.github.io/js/library/smooth-scroll.polyfills.min.js'></script>
<script defer src='https://aaron-mok.github.io/js/sticky-header.js'></script>
<script defer src='https://aaron-mok.github.io/js/smooth-scroll-init.js'></script>
<script defer src='https://aaron-mok.github.io/js/library/bootstrap.min.js'></script>





<script>
  window.si = window.si || function () { (window.siq = window.siq || []).push(arguments); };
</script>



</body>

</html>
