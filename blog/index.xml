<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on </title>
    <link>https://aaron-mok.github.io/blog/</link>
    <description>Recent content in Blogs on </description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 08 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://aaron-mok.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Optics tooling and mounts</title>
      <link>https://aaron-mok.github.io/blog/solidworks_showcase/</link>
      <pubDate>Wed, 08 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://aaron-mok.github.io/blog/solidworks_showcase/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://aaron-mok.github.io/img/blog/Toolings/tooling_coverart.webp&#34; alt=&#34;ToF art&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;This blog post showcases some optical tooling and mounts I designed in SolidWorks and Fusion.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Light Detection and Ranging (LiDAR) (with Zemax simulation)</title>
      <link>https://aaron-mok.github.io/blog/lidar/</link>
      <pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://aaron-mok.github.io/blog/lidar/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://aaron-mok.github.io/img/blog/LiDAR/LiDAR.webp&#34; alt=&#34;ToF art&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;In last blog, I have discussed optical time-of-fligth (ToF) sensing and how it works. However, it is with a single emitter that emits a single beam of light and with single-pixel detector.&#xA;We can only measure ToF in a single point in space.&lt;/p&gt;&#xA;&lt;p&gt;How do we sense depth across an area?&#xA;Light Detection and Ranging (LiDAR) is the system based on ToF sensing that can measure depth across an area.&#xA;In this blog, I will (a) discuss LiDAR and (b) simulate a type of LiDAR, Flash LiDAR, using Zemax.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optical Time-of-Flight (ToF) sensing and lock-in detection</title>
      <link>https://aaron-mok.github.io/blog/time_of_flight/</link>
      <pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://aaron-mok.github.io/blog/time_of_flight/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://aaron-mok.github.io/img/blog/ToF/time_of_flight.webp&#34; alt=&#34;ToF art&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Distance measurements is important for a lot of applications, such as 3D imaging and depth sensing. One common method for distance measurement is by using optical time-of-flight. I will introduce two concepts: (a) The time-of-flight Principle and (b) lock-in detection/amplification to explain how it works.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Dual Excitation with Adaptive Excitation Polygon-scanning Multiphoton Microscope (DEEPscope)</title>
      <link>https://aaron-mok.github.io/blog/deepscope/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://aaron-mok.github.io/blog/deepscope/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://aaron-mok.github.io/img/blog/Mouse3Drender.gif&#34; alt=&#34;DEEPscope Animation&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;In neuroscience research, imaging neuronal activity in the deep brain is crucial for understanding neurological diseases. However, as imaging depth increases, the field of view usually decreases exponentially. We have improved the fluorescence signal generation efficiency of three-photon microscopy, achieving an imaging field two order of magnitudes larger than traditional three-photon microscopes in deep brain regions with cellular resolution.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
